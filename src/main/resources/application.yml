
profiles:
  now: local

server:
  shutdown: graceful
  servlet:
    context-path: /
    encoding:
      charset: UTF-8
  tomcat:
    uri-encoding: UTF-8
  port: 8899 # 9999

spring:
  boot:
    mainClass: com.boot3kotlin.Boot3KotlinApplication
  mvc:
    pathmatch:
      matching-strategy: ant_path_matcher
  application:
    name: springboot3-kotlin
  main:
    allow-bean-definition-overriding: true
#  r2dbc:
#    url: r2dbc:pool:mysql://localhost:3306/boot3?characterEncoding=UTF-8&useSSL=false&allowPublicKeyRetrieval=true&useUnicode=true&serverTimezone=Asia/Seoul
#    username: boot3
#    password: boot3
  datasource:
    driver-class-name: net.sf.log4jdbc.sql.jdbcapi.DriverSpy
    username: boot3
    password: boot3
    hikari:
      connection-timeout: 50000
      driver-class-name: net.sf.log4jdbc.sql.jdbcapi.DriverSpy
    url: jdbc:log4jdbc:mariadb://localhost:3306/boot3-kotlin?characterEncoding=UTF-8&useSSL=false&allowPublicKeyRetrieval=true&useUnicode=true&serverTimezone=Asia/Seoul
  jpa:
    hibernate:
      ddl-auto: create
    database-platform: org.hibernate.dialect.MariaDBDialect
    properties:
      hibernate:
        format_sql: true
    defer-datasource-initialization: true
    open-in-view: true
    show_sql: true
    format_sql: true
  servlet:
    multipart:
      enabled: true
      max-file-size: 100MB
      max-request-size: 100MB
  kafka:
    bootstrap-servers: 127.0.0.1:9092,127.0.0.1:9093,127.0.0.1:9094
    consumer:
      group-id: kafka-practice #컨슈머의 그룹id
      enable-auto-commit: true #데이터를 어디까지 읽었다는 offset을 주기적으로 저장할지 여부
      auto-offset-reset: latest #offset에 오류가 있을 경우 어디서부터 다시 할지 여부, ealiest: 맨처음부터 다시 읽는다 / latest: 이전꺼는 무시하고, 이제부터 들어오는 데이터부터 읽기 시작한다
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer #데이터를 kafka에서 받아서 사용하는 Key Decoder ClassStringDeserializer는 문자열 형태의 데이터에만 사용 가능
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      max-poll-records: 1000 #consumer가 한번에 가져오는 message 갯수
      text-group:
        gid: tgroup
        topic: text-topic
      data-group:
        gid: dgroup
        topic: data-topic
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer #데이터를 kafka로 전달할때 사용하는 Key Encoder ClassStringSerializer는 문자열 형태의 데이터에만 사용 가능
    template:
      default-topic: kafka-practice-topic #기본 설정 topic name
    text-topic: text-topic
    data-topic: data-topic
logging:
  level:
    org.springframework.r2dbc.core: debug

#  session:
#    storage-type: redis
#  redis:
#    host: localhost
#    port: 6379
#  kafka:
#    bootstrap-servers: localhost:9092
#    consumer:
#      group-id: sample-group

management:
  endpoints:
    web:
      exposure:
        include: '*'
        # exclude: threaddump, heapdump
  endpoint:
    health:
      show-details: always

###########################################
################### API ###################
###########################################
api:
  kakao:
    url: https://dapi.kakao.com
    authorization: KakaoAK
    key: a44497b0b4151ec0db211f5ae847b607
    aukey: KakaoAK a44497b0b4151ec0db211f5ae847b607
    path: /v2/search/blog
  naver:
    url: https://openapi.naver.com
    client-id: f522O2wr4C9VIqtAQsKU
    client-secret: PEmAsMI4x1
    path: /v1/search/blog.json